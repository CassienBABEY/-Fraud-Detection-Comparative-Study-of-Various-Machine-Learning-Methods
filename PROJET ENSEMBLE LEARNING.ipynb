{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cf081e",
   "metadata": {},
   "source": [
    "# <center> Ensemble Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183d4a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:42:59.807648Z",
     "start_time": "2023-10-15T17:42:58.942990Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ebcc6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Datasets infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1653eac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T23:29:01.305914Z",
     "start_time": "2023-10-13T23:29:01.270057Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>shape</th>\n",
       "      <th>X_test_shape</th>\n",
       "      <th>X_train_shape</th>\n",
       "      <th>y_test_shape</th>\n",
       "      <th>y_train_shape</th>\n",
       "      <th>Train_dist_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle_source_cate_0</td>\n",
       "      <td>(54744, 52)</td>\n",
       "      <td>(13686, 51)</td>\n",
       "      <td>(41058, 51)</td>\n",
       "      <td>(13686, 2)</td>\n",
       "      <td>(41058, 2)</td>\n",
       "      <td>10.041892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle_source_cate_1</td>\n",
       "      <td>(54744, 52)</td>\n",
       "      <td>(13686, 51)</td>\n",
       "      <td>(41058, 51)</td>\n",
       "      <td>(13686, 2)</td>\n",
       "      <td>(41058, 2)</td>\n",
       "      <td>9.956647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kaggle_source_cate_2</td>\n",
       "      <td>(54744, 52)</td>\n",
       "      <td>(13686, 51)</td>\n",
       "      <td>(41058, 51)</td>\n",
       "      <td>(13686, 2)</td>\n",
       "      <td>(41058, 2)</td>\n",
       "      <td>9.832432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kaggle_source_cate_3</td>\n",
       "      <td>(54744, 52)</td>\n",
       "      <td>(13686, 51)</td>\n",
       "      <td>(41058, 51)</td>\n",
       "      <td>(13686, 2)</td>\n",
       "      <td>(41058, 2)</td>\n",
       "      <td>9.815383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset        shape X_test_shape X_train_shape y_test_shape  \\\n",
       "0  kaggle_source_cate_0  (54744, 52)  (13686, 51)   (41058, 51)   (13686, 2)   \n",
       "1  kaggle_source_cate_1  (54744, 52)  (13686, 51)   (41058, 51)   (13686, 2)   \n",
       "2  kaggle_source_cate_2  (54744, 52)  (13686, 51)   (41058, 51)   (13686, 2)   \n",
       "3  kaggle_source_cate_3  (54744, 52)  (13686, 51)   (41058, 51)   (13686, 2)   \n",
       "\n",
       "  y_train_shape  Train_dist_label  \n",
       "0    (41058, 2)         10.041892  \n",
       "1    (41058, 2)          9.956647  \n",
       "2    (41058, 2)          9.832432  \n",
       "3    (41058, 2)          9.815383  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Liste des noms de fichiers\n",
    "dataset_files = ['data/kaggle_source_cate_{}_test.npy'.format(i) for i in range(4)]\n",
    "\n",
    "# Initialisez des listes pour stocker les données\n",
    "datasets = []\n",
    "X_test_shapes = []\n",
    "X_train_shapes = []\n",
    "y_test_shapes = []\n",
    "y_train_shapes = []\n",
    "train_dist_labels = []\n",
    "\n",
    "# Boucle à travers les fichiers\n",
    "for i, file_path in enumerate(dataset_files):\n",
    "    # Charger les données à partir du fichier\n",
    "    X_test = np.load(file_path)\n",
    "    y_test = np.load(file_path.replace('test.npy', 'test_label.npy'))\n",
    "    X_train = np.load(file_path.replace('test.npy', 'train.npy'))\n",
    "    y_train = np.load(file_path.replace('test.npy', 'train_label.npy'))\n",
    "    \n",
    "    # Ajoutez les données aux listes\n",
    "    datasets.append('kaggle_source_cate_{}'.format(i))\n",
    "    X_test_shapes.append(X_test.shape)\n",
    "    X_train_shapes.append(X_train.shape)\n",
    "    y_test_shapes.append(y_test.shape)\n",
    "    y_train_shapes.append(y_train.shape)\n",
    "    distribution = (np.sum(y_train[:, 1]) / y_train.shape[0]) * 100  # Supposant que la colonne 1 de y soit la classe\n",
    "    train_dist_labels.append(distribution)\n",
    "\n",
    "# Créer un DataFrame\n",
    "data = {\n",
    "    'dataset': datasets,\n",
    "    'shape': [(np.sum(X_train_shape[0] + X_test_shape[0]), X_train_shape[1] + 1) for X_train_shape, X_test_shape in zip(X_train_shapes, X_test_shapes)],  # +1 pour la colonne y\n",
    "    'X_test_shape': X_test_shapes,\n",
    "    'X_train_shape': X_train_shapes,\n",
    "    'y_test_shape': y_test_shapes,\n",
    "    'y_train_shape': y_train_shapes,\n",
    "    'Train_dist_label': train_dist_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Affichez le DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957254c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5423542",
   "metadata": {},
   "source": [
    "Nous créeons une fonction pour charger les données et preprocess les y pour ne garder que la 2e colonne (classe) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e655b2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:01.693111Z",
     "start_time": "2023-10-15T17:43:01.689008Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(dataset_number):\n",
    "    \"\"\"\n",
    "    Charge les données et effectue le prétraitement pour un dataset donné.\n",
    "\n",
    "    Args:\n",
    "    dataset_number (int): Numéro du dataset (de 0 à 3).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: X_train, X_test, y_train, y_test prétraités.\n",
    "    \"\"\"\n",
    "\n",
    "    # Charger les données\n",
    "    X_test = np.load(f'data/kaggle_source_cate_{dataset_number}_test.npy')\n",
    "    y_test = np.load(f'data/kaggle_source_cate_{dataset_number}_test_label.npy')\n",
    "    X_train = np.load(f'data/kaggle_source_cate_{dataset_number}_train.npy')\n",
    "    y_train = np.load(f'data/kaggle_source_cate_{dataset_number}_train_label.npy')\n",
    "\n",
    "    # Garder uniquement la deuxième colonne de y\n",
    "    y_train = y_train[:, 1]\n",
    "    y_test = y_test[:, 1]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bb937e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:03.779392Z",
     "start_time": "2023-10-15T17:43:03.737316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset 1\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = load_and_preprocess_data(0)\n",
    "\n",
    "# Dataset 2\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = load_and_preprocess_data(1)\n",
    "\n",
    "# Dataset 3\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = load_and_preprocess_data(2)\n",
    "\n",
    "# Dataset 4\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = load_and_preprocess_data(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef540977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T23:25:17.330096Z",
     "start_time": "2023-10-13T23:25:17.147907Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## X_train data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c9ab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous explorons rapidement la distribution des données pour de potentiels pré-traitement.\n",
    "Les datasets n'ont aucunes valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3f2273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T23:33:00.915253Z",
     "start_time": "2023-10-13T23:32:59.174193Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modifier le X_train pour observer la distribution des autres set d'entrainement\n",
    "\n",
    "test = pd.DataFrame(X_train_0)\n",
    "\n",
    "# Sélectionnez les dix premières variables (colonnes 0 à 9)\n",
    "subset_data = test.iloc[:, 0:51]\n",
    "\n",
    "# Créez des boxplots pour chaque colonne\n",
    "plt.figure(figsize=(12, 8))\n",
    "subset_data.boxplot()\n",
    "plt.title('Distribution des variables (Boxplots)')\n",
    "plt.ylabel('Valeurs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1dbba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Il semble qu'une normalisation soit nécessaire avant l'entrainement de nos modèles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9caece",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81899cc",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b5dde44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:12.161818Z",
     "start_time": "2023-10-15T17:43:12.157615Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Définissez les ensembles de données\n",
    "datasets = ['X_train_0', 'X_train_1', 'X_train_2', 'X_train_3']\n",
    "test_datasets = ['X_test_0', 'X_test_1', 'X_test_2', 'X_test_3']\n",
    "labels = ['y_train_0', 'y_train_1', 'y_train_2', 'y_train_3']\n",
    "test_labels = ['y_test_0', 'y_test_1', 'y_test_2', 'y_test_3']\n",
    "\n",
    "# Créez un objet StratifiedKFold pour la validation croisée en spécifiant un random state pour avoir les mêmes folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47bf4b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae3cc103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:22:57.213584Z",
     "start_time": "2023-10-14T01:14:15.300903Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dataset                  Model Penalty     C  F1 Score  \\\n",
      "0    X_train_0  Régression Logistique      l2   0.1  0.000000   \n",
      "1    X_train_0  Régression Logistique      l1   0.1  0.000000   \n",
      "2    X_train_0  Régression Logistique      l2   1.0  0.035286   \n",
      "3    X_train_0  Régression Logistique      l1   1.0  0.351231   \n",
      "4    X_train_0  Régression Logistique      l2  10.0  0.150354   \n",
      "..         ...                    ...     ...   ...       ...   \n",
      "115  X_train_3  Régression Logistique      l1   0.1  0.000000   \n",
      "116  X_train_3  Régression Logistique      l2   1.0  0.038518   \n",
      "117  X_train_3  Régression Logistique      l1   1.0  0.364886   \n",
      "118  X_train_3  Régression Logistique      l2  10.0  0.155329   \n",
      "119  X_train_3  Régression Logistique      l1  10.0  0.535591   \n",
      "\n",
      "     Training Time (s)  \n",
      "0            24.885809  \n",
      "1            24.885815  \n",
      "2            24.885818  \n",
      "3            24.885820  \n",
      "4            24.885823  \n",
      "..                 ...  \n",
      "115          25.955982  \n",
      "116          25.955985  \n",
      "117          25.955987  \n",
      "118          25.955990  \n",
      "119          25.955992  \n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles et les paramètres à rechercher\n",
    "models = {\n",
    "    'Régression Logistique': (LogisticRegression(solver='liblinear'), {\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'C': [0.1, 1, 10]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de régression logistique\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            # Créer un objet GridSearchCV\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv=skf)\n",
    "\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Exécuter la recherche sur la grille\n",
    "            grid_search.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "            # Obtenir les résultats de la validation croisée\n",
    "            cv_results = grid_search.cv_results_\n",
    "            penalties = cv_results['param_penalty']\n",
    "            C_values = cv_results['param_C']\n",
    "            f1_scores = cv_results['mean_test_score']\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            for penalty, C, f1 in zip(penalties, C_values, f1_scores):\n",
    "                results.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'Penalty': penalty,\n",
    "                    'C': C,\n",
    "                    'F1 Score': f1,\n",
    "                    'Training Time (s)': time.time() - start_time\n",
    "                })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f70b0c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:40:36.232186Z",
     "start_time": "2023-10-14T01:40:36.218738Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.885809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.885815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>24.885818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351231</td>\n",
       "      <td>24.885820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.150354</td>\n",
       "      <td>24.885823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.955982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038518</td>\n",
       "      <td>25.955985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.364886</td>\n",
       "      <td>25.955987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.155329</td>\n",
       "      <td>25.955990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Régression Logistique</td>\n",
       "      <td>l1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.535591</td>\n",
       "      <td>25.955992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset                  Model Penalty     C  F1 Score  \\\n",
       "0    X_train_0  Régression Logistique      l2   0.1  0.000000   \n",
       "1    X_train_0  Régression Logistique      l1   0.1  0.000000   \n",
       "2    X_train_0  Régression Logistique      l2   1.0  0.035286   \n",
       "3    X_train_0  Régression Logistique      l1   1.0  0.351231   \n",
       "4    X_train_0  Régression Logistique      l2  10.0  0.150354   \n",
       "..         ...                    ...     ...   ...       ...   \n",
       "115  X_train_3  Régression Logistique      l1   0.1  0.000000   \n",
       "116  X_train_3  Régression Logistique      l2   1.0  0.038518   \n",
       "117  X_train_3  Régression Logistique      l1   1.0  0.364886   \n",
       "118  X_train_3  Régression Logistique      l2  10.0  0.155329   \n",
       "119  X_train_3  Régression Logistique      l1  10.0  0.535591   \n",
       "\n",
       "     Training Time (s)  \n",
       "0            24.885809  \n",
       "1            24.885815  \n",
       "2            24.885818  \n",
       "3            24.885820  \n",
       "4            24.885823  \n",
       "..                 ...  \n",
       "115          25.955982  \n",
       "116          25.955985  \n",
       "117          25.955987  \n",
       "118          25.955990  \n",
       "119          25.955992  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692ec21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:42:51.895720Z",
     "start_time": "2023-10-14T01:42:51.886012Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dataset                  Model Penalty     C  F1 Score  Training Time (s)\n",
      "0  X_train_2  Régression Logistique      l1  10.0  0.536881          28.302266\n",
      "1  X_train_3  Régression Logistique      l1  10.0  0.535591          25.955992\n",
      "2  X_train_1  Régression Logistique      l1  10.0  0.534838          25.420057\n",
      "3  X_train_0  Régression Logistique      l1  10.0  0.523064          27.291655\n"
     ]
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "results_df_sorted = results_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "best_results_df = results_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "best_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "print(best_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500551b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Les meilleurs paramètres pour nos 4 datasets semblent être une pénalité Lasso de 10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd88fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:45:13.348378Z",
     "start_time": "2023-10-14T01:45:13.344981Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Bagging Classifier Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5003b721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:54:06.079610Z",
     "start_time": "2023-10-14T01:47:34.655538Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.533871</td>\n",
       "      <td>20.673842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.559677</td>\n",
       "      <td>19.962358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.508278</td>\n",
       "      <td>19.066781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>18.597045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.517129</td>\n",
       "      <td>20.187070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.528830</td>\n",
       "      <td>19.490861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.536626</td>\n",
       "      <td>18.187291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.533662</td>\n",
       "      <td>19.564363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.535627</td>\n",
       "      <td>20.405990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>19.906570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>19.425342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.574657</td>\n",
       "      <td>18.802217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.562092</td>\n",
       "      <td>21.025059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>17.321709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>19.931859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.531987</td>\n",
       "      <td>19.702111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.534768</td>\n",
       "      <td>18.480745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.557724</td>\n",
       "      <td>19.176919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.534768</td>\n",
       "      <td>21.112565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.515533</td>\n",
       "      <td>19.853884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset                                              Model  F1 Score  \\\n",
       "0   X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.533871   \n",
       "1   X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.559677   \n",
       "2   X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.508278   \n",
       "3   X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.532468   \n",
       "4   X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.517129   \n",
       "5   X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.528830   \n",
       "6   X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.536626   \n",
       "7   X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.533662   \n",
       "8   X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.535627   \n",
       "9   X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.543831   \n",
       "10  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.505102   \n",
       "11  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.574657   \n",
       "12  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.562092   \n",
       "13  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.524400   \n",
       "14  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.527778   \n",
       "15  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.531987   \n",
       "16  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.534768   \n",
       "17  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.557724   \n",
       "18  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.534768   \n",
       "19  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.515533   \n",
       "\n",
       "    Training Time (s)  \n",
       "0           20.673842  \n",
       "1           19.962358  \n",
       "2           19.066781  \n",
       "3           18.597045  \n",
       "4           20.187070  \n",
       "5           19.490861  \n",
       "6           18.187291  \n",
       "7           19.564363  \n",
       "8           20.405990  \n",
       "9           19.906570  \n",
       "10          19.425342  \n",
       "11          18.802217  \n",
       "12          21.025059  \n",
       "13          17.321709  \n",
       "14          19.931859  \n",
       "15          19.702111  \n",
       "16          18.480745  \n",
       "17          19.176919  \n",
       "18          21.112565  \n",
       "19          19.853884  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Définir le modèle de régression logistique L1 avec C=10\n",
    "base_estimator = LogisticRegression(solver='liblinear', penalty='l1', C=10)\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de Bagging avec le modèle de régression logistique L1 et C=10\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels,\n",
    "                                                    test_datasets,\n",
    "                                                    test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        # Créer un Bagging Classifier avec le modèle de régression logistique L1 et C=10\n",
    "        bagging_model = BaggingClassifier(base_estimator=base_estimator,\n",
    "                                          random_state=42)\n",
    "\n",
    "        # Mesurer le temps d'exécution\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        bagging_model.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "        # Prédire sur les données de test\n",
    "        y_pred = bagging_model.predict(X_test_fold_normalized)\n",
    "\n",
    "        # Calculer le score F1 pour les prédictions\n",
    "        f1 = f1_score(y_test_fold, y_pred)\n",
    "\n",
    "        # Ajouter les résultats à la liste\n",
    "        results.append({\n",
    "            'Dataset': dataset,\n",
    "            'Model': 'Bagging Classifier (Régression Logistique L1, C=10)',\n",
    "            'F1 Score': f1,\n",
    "            'Training Time (s)': time.time() - start_time\n",
    "        })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09137708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:58:55.596698Z",
     "start_time": "2023-10-14T01:58:55.585205Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.574657</td>\n",
       "      <td>18.802217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.559677</td>\n",
       "      <td>19.962358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.557724</td>\n",
       "      <td>19.176919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Bagging Classifier (Régression Logistique L1, ...</td>\n",
       "      <td>0.543831</td>\n",
       "      <td>19.906570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                                              Model  F1 Score  \\\n",
       "0  X_train_2  Bagging Classifier (Régression Logistique L1, ...  0.574657   \n",
       "1  X_train_0  Bagging Classifier (Régression Logistique L1, ...  0.559677   \n",
       "2  X_train_3  Bagging Classifier (Régression Logistique L1, ...  0.557724   \n",
       "3  X_train_1  Bagging Classifier (Régression Logistique L1, ...  0.543831   \n",
       "\n",
       "   Training Time (s)  \n",
       "0          18.802217  \n",
       "1          19.962358  \n",
       "2          19.176919  \n",
       "3          19.906570  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "Bagg_df_sorted = results_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "Bagging_results = Bagg_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "Bagging_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "Bagging_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cfad0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd8e9c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T11:02:35.252422Z",
     "start_time": "2023-10-14T02:27:27.992668Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708054</td>\n",
       "      <td>1693.073853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710594</td>\n",
       "      <td>1693.073862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>1693.073867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.706645</td>\n",
       "      <td>1693.073871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.708245</td>\n",
       "      <td>1693.073875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.705052</td>\n",
       "      <td>1458.375699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.708152</td>\n",
       "      <td>1458.375703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.695029</td>\n",
       "      <td>1458.375706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702834</td>\n",
       "      <td>1458.375710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.694762</td>\n",
       "      <td>1458.375713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset                     Model  n_estimators  max_depth  \\\n",
       "0    X_train_0  Random Forest Classifier            50        NaN   \n",
       "1    X_train_0  Random Forest Classifier           100        NaN   \n",
       "2    X_train_0  Random Forest Classifier           200        NaN   \n",
       "3    X_train_0  Random Forest Classifier            50        NaN   \n",
       "4    X_train_0  Random Forest Classifier           100        NaN   \n",
       "..         ...                       ...           ...        ...   \n",
       "535  X_train_3  Random Forest Classifier           100       20.0   \n",
       "536  X_train_3  Random Forest Classifier           200       20.0   \n",
       "537  X_train_3  Random Forest Classifier            50       20.0   \n",
       "538  X_train_3  Random Forest Classifier           100       20.0   \n",
       "539  X_train_3  Random Forest Classifier           200       20.0   \n",
       "\n",
       "     min_samples_split  F1 Score  Training Time (s)  \n",
       "0                    2  0.708054        1693.073853  \n",
       "1                    2  0.710594        1693.073862  \n",
       "2                    2  0.717518        1693.073867  \n",
       "3                    5  0.706645        1693.073871  \n",
       "4                    5  0.708245        1693.073875  \n",
       "..                 ...       ...                ...  \n",
       "535                  5  0.705052        1458.375699  \n",
       "536                  5  0.708152        1458.375703  \n",
       "537                 10  0.695029        1458.375706  \n",
       "538                 10  0.702834        1458.375710  \n",
       "539                 10  0.694762        1458.375713  \n",
       "\n",
       "[540 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Définir les modèles et les paramètres à rechercher\n",
    "models = {\n",
    "    'Random Forest Classifier': (RandomForestClassifier(), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de Random Forest Classifier\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            # Créer un objet GridSearchCV\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv=skf)\n",
    "\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Exécuter la recherche sur la grille\n",
    "            grid_search.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "            # Obtenir les résultats de la validation croisée\n",
    "            cv_results = grid_search.cv_results_\n",
    "            estimators = cv_results['param_n_estimators']\n",
    "            max_depths = cv_results['param_max_depth']\n",
    "            min_samples_splits = cv_results['param_min_samples_split']\n",
    "            f1_scores = cv_results['mean_test_score']\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            for estimator, max_depth, min_samples_split, f1 in zip(estimators, max_depths, min_samples_splits, f1_scores):\n",
    "                results.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'n_estimators': estimator,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'F1 Score': f1,\n",
    "                    'Training Time (s)': time.time() - start_time\n",
    "                })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "RFC_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "RFC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cff44f93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T11:18:37.184345Z",
     "start_time": "2023-10-14T11:18:37.172782Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.726746</td>\n",
       "      <td>1677.992775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721515</td>\n",
       "      <td>1444.336066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>1789.925151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.711951</td>\n",
       "      <td>1458.375692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                     Model  n_estimators  max_depth  \\\n",
       "0  X_train_1  Random Forest Classifier           200       20.0   \n",
       "1  X_train_2  Random Forest Classifier           200        NaN   \n",
       "2  X_train_0  Random Forest Classifier            50        NaN   \n",
       "3  X_train_3  Random Forest Classifier           200       20.0   \n",
       "\n",
       "   min_samples_split  F1 Score  Training Time (s)  \n",
       "0                  2  0.726746        1677.992775  \n",
       "1                  2  0.721515        1444.336066  \n",
       "2                  2  0.721492        1789.925151  \n",
       "3                  2  0.711951        1458.375692  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "RFC_df_sorted = RFC_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "RFC_results = RFC_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "RFC_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "RFC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92780b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e823fa8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T14:50:39.934127Z",
     "start_time": "2023-10-14T11:19:01.902367Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.129558</td>\n",
       "      <td>548.418949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>548.418954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.387466</td>\n",
       "      <td>548.418957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.433564</td>\n",
       "      <td>548.418960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.515298</td>\n",
       "      <td>548.418962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.532161</td>\n",
       "      <td>611.798910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.584003</td>\n",
       "      <td>611.798913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556580</td>\n",
       "      <td>611.798916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.594396</td>\n",
       "      <td>611.798918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628234</td>\n",
       "      <td>611.798921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset                Model  n_estimators  learning_rate  F1 Score  \\\n",
       "0    X_train_0  AdaBoost Classifier            50            0.1  0.129558   \n",
       "1    X_train_0  AdaBoost Classifier           100            0.1  0.268700   \n",
       "2    X_train_0  AdaBoost Classifier           200            0.1  0.387466   \n",
       "3    X_train_0  AdaBoost Classifier            50            0.5  0.433564   \n",
       "4    X_train_0  AdaBoost Classifier           100            0.5  0.515298   \n",
       "..         ...                  ...           ...            ...       ...   \n",
       "175  X_train_3  AdaBoost Classifier           100            0.5  0.532161   \n",
       "176  X_train_3  AdaBoost Classifier           200            0.5  0.584003   \n",
       "177  X_train_3  AdaBoost Classifier            50            1.0  0.556580   \n",
       "178  X_train_3  AdaBoost Classifier           100            1.0  0.594396   \n",
       "179  X_train_3  AdaBoost Classifier           200            1.0  0.628234   \n",
       "\n",
       "     Training Time (s)  \n",
       "0           548.418949  \n",
       "1           548.418954  \n",
       "2           548.418957  \n",
       "3           548.418960  \n",
       "4           548.418962  \n",
       "..                 ...  \n",
       "175         611.798910  \n",
       "176         611.798913  \n",
       "177         611.798916  \n",
       "178         611.798918  \n",
       "179         611.798921  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Définir les modèles et les paramètres à rechercher\n",
    "models = {\n",
    "    'AdaBoost Classifier': (AdaBoostClassifier(), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.5, 1.0]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de AdaBoost Classifier\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération si nécessaire\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            # Créer un objet GridSearchCV\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=make_scorer(f1_score), cv=skf)\n",
    "\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Exécuter la recherche sur la grille\n",
    "            grid_search.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "            # Obtenir les résultats de la validation croisée\n",
    "            cv_results = grid_search.cv_results_\n",
    "            estimators = cv_results['param_n_estimators']\n",
    "            learning_rates = cv_results['param_learning_rate']\n",
    "            f1_scores = cv_results['mean_test_score']\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            for estimator, learning_rate, f1 in zip(estimators, learning_rates, f1_scores):\n",
    "                results.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'n_estimators': estimator,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'F1 Score': f1,\n",
    "                    'Training Time (s)': time.time() - start_time\n",
    "                })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "AdaBoost_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "AdaBoost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b277003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T15:33:41.301653Z",
     "start_time": "2023-10-14T15:33:41.278342Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628623</td>\n",
       "      <td>622.204989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622900</td>\n",
       "      <td>557.408932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622351</td>\n",
       "      <td>595.046221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621433</td>\n",
       "      <td>468.913669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                Model  n_estimators  learning_rate  F1 Score  \\\n",
       "0  X_train_3  AdaBoost Classifier           200            1.0  0.628623   \n",
       "1  X_train_1  AdaBoost Classifier           200            1.0  0.622900   \n",
       "2  X_train_2  AdaBoost Classifier           200            1.0  0.622351   \n",
       "3  X_train_0  AdaBoost Classifier           200            1.0  0.621433   \n",
       "\n",
       "   Training Time (s)  \n",
       "0         622.204989  \n",
       "1         557.408932  \n",
       "2         595.046221  \n",
       "3         468.913669  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "AdaBoost_df_sorted = AdaBoost_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "AdaBoost_results = AdaBoost_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "AdaBoost_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "AdaBoost_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed92228",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8176ab4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T19:48:28.868013Z",
     "start_time": "2023-10-14T17:10:50.370205Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>C</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>457.272151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>457.272158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>457.272161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>457.272164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>457.272166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510.290427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510.290431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>510.290433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.103049</td>\n",
       "      <td>510.290436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.163914</td>\n",
       "      <td>510.290438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset           Model     C  Kernel  F1 Score  Training Time (s)\n",
       "0    X_train_0  SVM Classifier   0.1  linear  0.000000         457.272151\n",
       "1    X_train_0  SVM Classifier   0.1     rbf  0.000000         457.272158\n",
       "2    X_train_0  SVM Classifier   1.0  linear  0.000000         457.272161\n",
       "3    X_train_0  SVM Classifier   1.0     rbf  0.000000         457.272164\n",
       "4    X_train_0  SVM Classifier  10.0  linear  0.108963         457.272166\n",
       "..         ...             ...   ...     ...       ...                ...\n",
       "115  X_train_3  SVM Classifier   0.1     rbf  0.000000         510.290427\n",
       "116  X_train_3  SVM Classifier   1.0  linear  0.000000         510.290431\n",
       "117  X_train_3  SVM Classifier   1.0     rbf  0.000000         510.290433\n",
       "118  X_train_3  SVM Classifier  10.0  linear  0.103049         510.290436\n",
       "119  X_train_3  SVM Classifier  10.0     rbf  0.163914         510.290438\n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Définir les modèles et les paramètres à rechercher\n",
    "models = {\n",
    "    'SVM Classifier': (SVC(), {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de SVM Classifier\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération si nécessaire\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            # Créer un objet GridSearchCV\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=make_scorer(f1_score), cv=skf)\n",
    "\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Exécuter la recherche sur la grille\n",
    "            grid_search.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "            # Obtenir les résultats de la validation croisée\n",
    "            cv_results = grid_search.cv_results_\n",
    "            C_values = cv_results['param_C']\n",
    "            kernels = cv_results['param_kernel']\n",
    "            f1_scores = cv_results['mean_test_score']\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            for C, kernel, f1 in zip(C_values, kernels, f1_scores):\n",
    "                results.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'C': C,\n",
    "                    'Kernel': kernel,\n",
    "                    'F1 Score': f1,\n",
    "                    'Training Time (s)': time.time() - start_time\n",
    "                })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "SVM_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "SVM_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36a167b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T20:19:06.469437Z",
     "start_time": "2023-10-14T20:19:06.457868Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>C</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.171368</td>\n",
       "      <td>405.762930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.170852</td>\n",
       "      <td>492.526559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.169534</td>\n",
       "      <td>457.272170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>SVM Classifier</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.168227</td>\n",
       "      <td>526.883648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset           Model     C Kernel  F1 Score  Training Time (s)\n",
       "0  X_train_1  SVM Classifier  10.0    rbf  0.171368         405.762930\n",
       "1  X_train_2  SVM Classifier  10.0    rbf  0.170852         492.526559\n",
       "2  X_train_0  SVM Classifier  10.0    rbf  0.169534         457.272170\n",
       "3  X_train_3  SVM Classifier  10.0    rbf  0.168227         526.883648"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "SVM_df_sorted = SVM_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "SVM_results = SVM_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "SVM_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "SVM_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5579f1a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Stacking de SVC avec un Random Forest en sortie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fa6dd43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T01:37:39.141431Z",
     "start_time": "2023-10-15T00:26:30.665259Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.679374</td>\n",
       "      <td>233.212766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.691156</td>\n",
       "      <td>256.996865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.694272</td>\n",
       "      <td>259.911151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.696125</td>\n",
       "      <td>260.612454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.654494</td>\n",
       "      <td>256.842827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>240.205875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.707015</td>\n",
       "      <td>205.085048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.698678</td>\n",
       "      <td>197.259749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.686897</td>\n",
       "      <td>198.818977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.718793</td>\n",
       "      <td>198.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.679056</td>\n",
       "      <td>196.458933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.704577</td>\n",
       "      <td>196.751143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.694308</td>\n",
       "      <td>196.526736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.669986</td>\n",
       "      <td>196.401761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>195.390435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>197.820054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.682823</td>\n",
       "      <td>198.510863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.693111</td>\n",
       "      <td>194.381808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.673835</td>\n",
       "      <td>194.889496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>193.688118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset                Model  F1 Score  Training Time (s)\n",
       "0   X_train_0  Stacking (SVM + RF)  0.679374         233.212766\n",
       "1   X_train_0  Stacking (SVM + RF)  0.691156         256.996865\n",
       "2   X_train_0  Stacking (SVM + RF)  0.694272         259.911151\n",
       "3   X_train_0  Stacking (SVM + RF)  0.696125         260.612454\n",
       "4   X_train_0  Stacking (SVM + RF)  0.654494         256.842827\n",
       "5   X_train_1  Stacking (SVM + RF)  0.691892         240.205875\n",
       "6   X_train_1  Stacking (SVM + RF)  0.707015         205.085048\n",
       "7   X_train_1  Stacking (SVM + RF)  0.698678         197.259749\n",
       "8   X_train_1  Stacking (SVM + RF)  0.686897         198.818977\n",
       "9   X_train_1  Stacking (SVM + RF)  0.718793         198.159722\n",
       "10  X_train_2  Stacking (SVM + RF)  0.679056         196.458933\n",
       "11  X_train_2  Stacking (SVM + RF)  0.704577         196.751143\n",
       "12  X_train_2  Stacking (SVM + RF)  0.694308         196.526736\n",
       "13  X_train_2  Stacking (SVM + RF)  0.669986         196.401761\n",
       "14  X_train_2  Stacking (SVM + RF)  0.696203         195.390435\n",
       "15  X_train_3  Stacking (SVM + RF)  0.673611         197.820054\n",
       "16  X_train_3  Stacking (SVM + RF)  0.682823         198.510863\n",
       "17  X_train_3  Stacking (SVM + RF)  0.693111         194.381808\n",
       "18  X_train_3  Stacking (SVM + RF)  0.673835         194.889496\n",
       "19  X_train_3  Stacking (SVM + RF)  0.677143         193.688118"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Définir les modèles de base\n",
    "base_models = [\n",
    "    ('SVM Classifier', SVC(C=10, kernel='rbf')),  # Utilisez les meilleurs hyperparamètres trouvés\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2,  random_state=42))  # Paramètres arbitraires\n",
    "]\n",
    "\n",
    "# Initialiser le modèle de méta-classification (Random Forest)\n",
    "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Paramètres arbitraires\n",
    "\n",
    "# Initialiser le modèle de stacking avec les modèles de base et le modèle de méta-classification\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de stacking\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération si nécessaire\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        # Mesurer le temps d'exécution\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Entraîner le modèle de stacking\n",
    "        stacking_model.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "        # Évaluer le modèle sur les données de test\n",
    "        f1_score_result = f1_score(y_test_fold, stacking_model.predict(X_test_fold_normalized))\n",
    "\n",
    "        # Ajouter les résultats à la liste\n",
    "        results.append({\n",
    "            'Dataset': dataset,\n",
    "            'Model': 'Stacking (SVM + RF)',\n",
    "            'F1 Score': f1_score_result,  # Utilisez un nom différent ici\n",
    "            'Training Time (s)': time.time() - start_time\n",
    "        })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "stacking_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "stacking_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb5e9a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T09:45:14.641283Z",
     "start_time": "2023-10-15T09:45:14.623453Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.718793</td>\n",
       "      <td>198.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.704577</td>\n",
       "      <td>196.751143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.696125</td>\n",
       "      <td>260.612454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>Stacking (SVM + RF)</td>\n",
       "      <td>0.693111</td>\n",
       "      <td>194.381808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                Model  F1 Score  Training Time (s)\n",
       "0  X_train_1  Stacking (SVM + RF)  0.718793         198.159722\n",
       "1  X_train_2  Stacking (SVM + RF)  0.704577         196.751143\n",
       "2  X_train_0  Stacking (SVM + RF)  0.696125         260.612454\n",
       "3  X_train_3  Stacking (SVM + RF)  0.693111         194.381808"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "stacking_df_sorted = stacking_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "stacking_results = stacking_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "stacking_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "stacking_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd58e0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e1ce40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T00:14:28.879748Z",
     "start_time": "2023-10-14T23:23:11.404011Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.698837</td>\n",
       "      <td>213.325449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.717678</td>\n",
       "      <td>213.325454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.734072</td>\n",
       "      <td>213.325457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.725750</td>\n",
       "      <td>213.325460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>213.325462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.737638</td>\n",
       "      <td>129.322505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.747072</td>\n",
       "      <td>129.322507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710851</td>\n",
       "      <td>129.322510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.716664</td>\n",
       "      <td>129.322512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729116</td>\n",
       "      <td>129.322515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset               Model  n_estimators  learning_rate  F1 Score  \\\n",
       "0    X_train_0  XGBoost Classifier            50            0.1  0.698837   \n",
       "1    X_train_0  XGBoost Classifier           100            0.1  0.717678   \n",
       "2    X_train_0  XGBoost Classifier           200            0.1  0.734072   \n",
       "3    X_train_0  XGBoost Classifier            50            0.5  0.725750   \n",
       "4    X_train_0  XGBoost Classifier           100            0.5  0.743839   \n",
       "..         ...                 ...           ...            ...       ...   \n",
       "175  X_train_3  XGBoost Classifier           100            0.5  0.737638   \n",
       "176  X_train_3  XGBoost Classifier           200            0.5  0.747072   \n",
       "177  X_train_3  XGBoost Classifier            50            1.0  0.710851   \n",
       "178  X_train_3  XGBoost Classifier           100            1.0  0.716664   \n",
       "179  X_train_3  XGBoost Classifier           200            1.0  0.729116   \n",
       "\n",
       "     Training Time (s)  \n",
       "0           213.325449  \n",
       "1           213.325454  \n",
       "2           213.325457  \n",
       "3           213.325460  \n",
       "4           213.325462  \n",
       "..                 ...  \n",
       "175         129.322505  \n",
       "176         129.322507  \n",
       "177         129.322510  \n",
       "178         129.322512  \n",
       "179         129.322515  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Définir les modèles et les paramètres à rechercher\n",
    "models = {\n",
    "    'XGBoost Classifier': (XGBClassifier(), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.5, 1.0]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "# Parcourir chaque dataset et appliquer le modèle de XGBoost Classifier\n",
    "for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "    X_train, y_train = locals()[dataset], locals()[label]\n",
    "    X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # Normaliser les données d'entraînement à chaque itération si nécessaire\n",
    "        norm = Normalizer()\n",
    "        X_train_fold_normalized = norm.fit_transform(X_train_fold)\n",
    "        X_test_fold_normalized = norm.transform(X_test_fold)\n",
    "\n",
    "        for model_name, (model, param_grid) in models.items():\n",
    "            # Créer un objet GridSearchCV\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=make_scorer(f1_score), cv=skf)\n",
    "\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Exécuter la recherche sur la grille\n",
    "            grid_search.fit(X_train_fold_normalized, y_train_fold)\n",
    "\n",
    "            # Obtenir les résultats de la validation croisée\n",
    "            cv_results = grid_search.cv_results_\n",
    "            estimators = cv_results['param_n_estimators']\n",
    "            learning_rates = cv_results['param_learning_rate']\n",
    "            f1_scores = cv_results['mean_test_score']\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            for estimator, learning_rate, f1 in zip(estimators, learning_rates, f1_scores):\n",
    "                results.append({\n",
    "                    'Dataset': dataset,\n",
    "                    'Model': model_name,\n",
    "                    'n_estimators': estimator,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'F1 Score': f1,\n",
    "                    'Training Time (s)': time.time() - start_time\n",
    "                })\n",
    "\n",
    "# Créer un DataFrame à partir des résultats\n",
    "XGBoost_df = pd.DataFrame(results)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "XGBoost_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee1cd9f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T00:26:21.837578Z",
     "start_time": "2023-10-15T00:26:21.825539Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train_1</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752951</td>\n",
       "      <td>127.677812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train_2</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752653</td>\n",
       "      <td>131.431044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train_0</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752351</td>\n",
       "      <td>211.045275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train_3</td>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>161.961901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset               Model  n_estimators  learning_rate  F1 Score  \\\n",
       "0  X_train_1  XGBoost Classifier           200            0.5  0.752951   \n",
       "1  X_train_2  XGBoost Classifier           200            0.5  0.752653   \n",
       "2  X_train_0  XGBoost Classifier           200            0.5  0.752351   \n",
       "3  X_train_3  XGBoost Classifier           200            0.5  0.749788   \n",
       "\n",
       "   Training Time (s)  \n",
       "0         127.677812  \n",
       "1         131.431044  \n",
       "2         211.045275  \n",
       "3         161.961901  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trier le DataFrame par F1 Score dans l'ordre décroissant\n",
    "XGBoost_df_sorted = XGBoost_df.sort_values(by='F1 Score', ascending=False)\n",
    "\n",
    "# Supprimer les lignes en double basées sur le nom du dataset, en conservant uniquement la première occurrence (la meilleure)\n",
    "XGBoost_results = XGBoost_df_sorted.drop_duplicates(subset='Dataset', keep='first')\n",
    "\n",
    "# Réinitialiser les index du DataFrame résultant\n",
    "XGBoost_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Afficher le DataFrame contenant les meilleurs scores F1 pour chaque dataset\n",
    "XGBoost_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de7bc8",
   "metadata": {},
   "source": [
    "### 10 iterations final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff88f4",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25046fe6",
   "metadata": {},
   "source": [
    "On redéfinit les modèles avec les meilleurs hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d65d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:14.483991Z",
     "start_time": "2023-10-15T17:43:14.479346Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(solver='liblinear',\n",
    "                                               penalty='l1',\n",
    "                                               C=10)),\n",
    "    'Bagging (Logistic Regression)':\n",
    "    (BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear',\n",
    "                                                         penalty='l1',\n",
    "                                                         C=10),\n",
    "                       n_estimators=10,\n",
    "                       random_state=42)),\n",
    "    'Random Forest Classifier': (RandomForestClassifier(n_estimators=200,\n",
    "                                                        max_depth=20,\n",
    "                                                        min_samples_split=2)),\n",
    "    'AdaBoost Classifier': (AdaBoostClassifier(n_estimators=200,\n",
    "                                               learning_rate=1)),\n",
    "    'SVC': (SVC(C=10, kernel='rbf')),\n",
    "    'Stacking Classifier': (StackingClassifier(\n",
    "        estimators=[('SVC', SVC(C=10, kernel='rbf'))],\n",
    "        final_estimator=RandomForestClassifier(n_estimators=100,\n",
    "                                               random_state=42))),\n",
    "    'XGBoost Classifier': (XGBClassifier(n_estimators=200, learning_rate=0.5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b000157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:46.141612Z",
     "start_time": "2023-10-15T17:43:46.138448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialiser les normaliseurs\n",
    "norm = Normalizer()\n",
    "\n",
    "# Initialiser une liste pour stocker les résultats\n",
    "results = []\n",
    "resultsv2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87756ad",
   "metadata": {},
   "source": [
    "Training et Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f7bb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T17:43:27.031220Z",
     "start_time": "2023-10-15T17:43:19.839060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression dataset: X_train_0 Finish iteration 0\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Mesurer le temps d'entraînement\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Finish iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    331\u001b[0m     X,\n\u001b[1;32m    332\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m )\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[0;32m--> 473\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    492\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:141\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[1;32m    138\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    140\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1227\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1222\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[1;32m   1226\u001b[0m         )\n\u001b[0;32m-> 1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1222\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1221\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1222\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misspmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Effectuer 10 itérations pour chaque modèle sur chaque dataset\n",
    "for _ in range(10):\n",
    "    for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "        X_train, y_train = locals()[dataset], locals()[label]\n",
    "        X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "        # Normaliser les données\n",
    "        X_train_normalized = norm.fit_transform(X_train)\n",
    "        X_test_normalized = norm.transform(X_test)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Mesurer le temps d'entraînement\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train_normalized, y_train)\n",
    "            training_time = time.time() - start_time\n",
    "            print(f'Training {model_name} dataset: {dataset} Finish iteration {_}')\n",
    "\n",
    "            # Mesurer le temps de test\n",
    "            start_time = time.time()\n",
    "            y_pred = model.predict(X_test_normalized)\n",
    "            test_time = time.time() - start_time\n",
    "            print(f'Test {model_name} dataset: {dataset} Finish iteration {_}')\n",
    "\n",
    "            # Calculer le F1 score\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            results.append({\n",
    "                'Dataset': dataset,\n",
    "                'Model': model_name,\n",
    "                'F1 Score': f1,\n",
    "                'Training Time (s)': training_time,\n",
    "                'Test Time (s)': test_time\n",
    "            })\n",
    "            print('Table Finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a7c30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T20:41:30.048928Z",
     "start_time": "2023-10-15T17:43:50.039104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression dataset: X_train_0 Finish iteration 0\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 0\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 0\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 0\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 0\n",
      "Test SVC dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 0\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 0\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 0\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 0\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 0\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 0\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 0\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 0\n",
      "Test SVC dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 0\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 0\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 0\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 0\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 0\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 0\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 0\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 0\n",
      "Test SVC dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 0\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 0\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 0\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 0\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 0\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 0\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 0\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 0\n",
      "Test SVC dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 0\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 0\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 0\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 1\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 1\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 1\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 1\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 1\n",
      "Test SVC dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 1\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 1\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 1\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 1\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 1\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 1\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 1\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 1\n",
      "Test SVC dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 1\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 1\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 1\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 1\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 1\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 1\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 1\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 1\n",
      "Test SVC dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 1\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 1\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 1\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 1\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 1\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 1\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 1\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 1\n",
      "Test SVC dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 1\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 1\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 1\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 2\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 2\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 2\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 2\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 2\n",
      "Test SVC dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 2\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 2\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 2\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 2\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 2\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 2\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 2\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 2\n",
      "Test SVC dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 2\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 2\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 2\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 2\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 2\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 2\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 2\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 2\n",
      "Test SVC dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 2\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 2\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 2\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 2\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 2\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 2\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 2\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 2\n",
      "Test SVC dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 2\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 2\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 2\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 3\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 3\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 3\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 3\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 3\n",
      "Test SVC dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 3\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 3\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 3\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 3\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 3\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 3\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 3\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 3\n",
      "Test SVC dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 3\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 3\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 3\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 3\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 3\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 3\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 3\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 3\n",
      "Test SVC dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 3\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 3\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 3\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 3\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 3\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 3\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 3\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 3\n",
      "Test SVC dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 3\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 3\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 3\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 4\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 4\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 4\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 4\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 4\n",
      "Test SVC dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 4\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 4\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 4\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 4\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 4\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 4\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 4\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 4\n",
      "Test SVC dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 4\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 4\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 4\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 4\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 4\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 4\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 4\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 4\n",
      "Test SVC dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 4\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 4\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 4\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 4\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 4\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 4\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 4\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 4\n",
      "Test SVC dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 4\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 4\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 4\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 5\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 5\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 5\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 5\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 5\n",
      "Test SVC dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 5\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 5\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 5\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 5\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 5\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 5\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 5\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 5\n",
      "Test SVC dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 5\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 5\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 5\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 5\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 5\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 5\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 5\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 5\n",
      "Test SVC dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 5\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 5\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 5\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 5\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 5\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 5\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 5\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 5\n",
      "Test SVC dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 5\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 5\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 5\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 6\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 6\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 6\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 6\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 6\n",
      "Test SVC dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 6\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 6\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 6\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 6\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 6\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 6\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 6\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 6\n",
      "Test SVC dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 6\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 6\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 6\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 6\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 6\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 6\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 6\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 6\n",
      "Test SVC dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 6\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 6\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 6\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 6\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 6\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 6\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 6\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 6\n",
      "Test SVC dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 6\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 6\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 6\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 7\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 7\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 7\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 7\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 7\n",
      "Test SVC dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 7\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 7\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 7\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 7\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 7\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 7\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 7\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 7\n",
      "Test SVC dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 7\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 7\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 7\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 7\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 7\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 7\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 7\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 7\n",
      "Test SVC dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 7\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 7\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 7\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 7\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 7\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 7\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 7\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 7\n",
      "Test SVC dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 7\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 7\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 7\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 8\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 8\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 8\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 8\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 8\n",
      "Test SVC dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 8\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 8\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 8\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 8\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 8\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 8\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 8\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 8\n",
      "Test SVC dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 8\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 8\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 8\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 8\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 8\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 8\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 8\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 8\n",
      "Test SVC dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 8\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 8\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 8\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 8\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 8\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 8\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 8\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 8\n",
      "Test SVC dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 8\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 8\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 8\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_0 Finish iteration 9\n",
      "Test Logistic Regression dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 9\n",
      "Test Bagging (Logistic Regression) dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_0 Finish iteration 9\n",
      "Test Random Forest Classifier dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_0 Finish iteration 9\n",
      "Test AdaBoost Classifier dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_0 Finish iteration 9\n",
      "Test SVC dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_0 Finish iteration 9\n",
      "Test Stacking Classifier dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_0 Finish iteration 9\n",
      "Test XGBoost Classifier dataset: X_train_0 Finish iteration 9\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_1 Finish iteration 9\n",
      "Test Logistic Regression dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 9\n",
      "Test Bagging (Logistic Regression) dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_1 Finish iteration 9\n",
      "Test Random Forest Classifier dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_1 Finish iteration 9\n",
      "Test AdaBoost Classifier dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_1 Finish iteration 9\n",
      "Test SVC dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_1 Finish iteration 9\n",
      "Test Stacking Classifier dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_1 Finish iteration 9\n",
      "Test XGBoost Classifier dataset: X_train_1 Finish iteration 9\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_2 Finish iteration 9\n",
      "Test Logistic Regression dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 9\n",
      "Test Bagging (Logistic Regression) dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_2 Finish iteration 9\n",
      "Test Random Forest Classifier dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_2 Finish iteration 9\n",
      "Test AdaBoost Classifier dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_2 Finish iteration 9\n",
      "Test SVC dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_2 Finish iteration 9\n",
      "Test Stacking Classifier dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_2 Finish iteration 9\n",
      "Test XGBoost Classifier dataset: X_train_2 Finish iteration 9\n",
      "Table Finish\n",
      "Training Logistic Regression dataset: X_train_3 Finish iteration 9\n",
      "Test Logistic Regression dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassienbabey/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 9\n",
      "Test Bagging (Logistic Regression) dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n",
      "Training Random Forest Classifier dataset: X_train_3 Finish iteration 9\n",
      "Test Random Forest Classifier dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n",
      "Training AdaBoost Classifier dataset: X_train_3 Finish iteration 9\n",
      "Test AdaBoost Classifier dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n",
      "Training SVC dataset: X_train_3 Finish iteration 9\n",
      "Test SVC dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n",
      "Training Stacking Classifier dataset: X_train_3 Finish iteration 9\n",
      "Test Stacking Classifier dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n",
      "Training XGBoost Classifier dataset: X_train_3 Finish iteration 9\n",
      "Test XGBoost Classifier dataset: X_train_3 Finish iteration 9\n",
      "Table Finish\n"
     ]
    }
   ],
   "source": [
    "# Effectuer 10 itérations pour chaque modèle sur chaque dataset\n",
    "for _ in range(10):\n",
    "    for dataset, label, test_dataset, test_label in zip(datasets, labels, test_datasets, test_labels):\n",
    "        X_train, y_train = locals()[dataset], locals()[label]\n",
    "        X_test, y_test = locals()[test_dataset], locals()[test_label]\n",
    "\n",
    "        # Normaliser les données\n",
    "        X_train_normalized = norm.fit_transform(X_train)\n",
    "        X_test_normalized = norm.transform(X_test)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Mesurer le temps d'entraînement\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train_normalized, y_train)\n",
    "            training_time = time.time() - start_time\n",
    "            print(f'Training {model_name} dataset: {dataset} Finish iteration {_}')\n",
    "\n",
    "            # Mesurer le temps de test\n",
    "            start_time = time.time()\n",
    "            y_pred = model.predict(X_test_normalized)\n",
    "            test_time = time.time() - start_time\n",
    "            print(f'Test {model_name} dataset: {dataset} Finish iteration {_}')\n",
    "\n",
    "            # Calculer le F1 score et l'écart-type\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            f1_std = np.std(f1)\n",
    "\n",
    "            # Ajouter les résultats à la liste\n",
    "            resultsv2.append({\n",
    "                'Dataset': dataset,\n",
    "                'Model': model_name,\n",
    "                'F1 Score': f1,\n",
    "                'F1 Score Std': f1_std,\n",
    "                'Training Time (s)': training_time,\n",
    "                'Test Time (s)': test_time\n",
    "            })\n",
    "            print('Table Finish')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2709599",
   "metadata": {},
   "source": [
    "Préparation de la table de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30dadff9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T22:54:29.799207Z",
     "start_time": "2023-10-15T22:54:29.784521Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dfa  = pd.DataFrame(resultsv2)\n",
    "\n",
    "# Calculer la moyenne et l'écart-type du F1-score pour chaque modèle et chaque dataset\n",
    "f1score_summary_df = results_dfa.groupby(['Dataset', 'Model'])['F1 Score'].agg(['mean', 'std']).reset_index()\n",
    "f1score_summary_df.rename(columns={'mean': 'Model (F1 Score Mean)', 'std': 'Model (F1 Score Std)'}, inplace=True)\n",
    "\n",
    "# Calculer la moyenne et l'écart-type du temps de test pour chaque modèle et chaque dataset\n",
    "testtime_summary_df = results_dfa.groupby(['Dataset', 'Model'])['Test Time (s)'].agg(['mean', 'std']).reset_index()\n",
    "testtime_summary_df.rename(columns={'mean': 'Model (Test Time Mean)', 'std': 'Model (Test Time Std)'}, inplace=True)\n",
    "\n",
    "# Calculer la moyenne et l'écart-type du temps d'entraînement pour chaque modèle et chaque dataset\n",
    "trainingtime_summary_df = results_dfa.groupby(['Dataset', 'Model'])['Training Time (s)'].agg(['mean', 'std']).reset_index()\n",
    "trainingtime_summary_df.rename(columns={'mean': 'Model (Training Time Mean)', 'std': 'Model (Training Time Std)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d4ba89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T22:49:07.587515Z",
     "start_time": "2023-10-15T22:49:07.564116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <th>Bagging (Logistic Regression)</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Stacking Classifier</th>\n",
       "      <th>XGBoost Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset_0</th>\n",
       "      <td>0.64 ± 0.00</td>\n",
       "      <td>0.56 ± 0.00</td>\n",
       "      <td>0.56 ± 0.00</td>\n",
       "      <td>0.75 ± 0.00</td>\n",
       "      <td>0.23 ± 0.00</td>\n",
       "      <td>0.44 ± 0.00</td>\n",
       "      <td>0.79 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_1</th>\n",
       "      <td>0.63 ± 0.00</td>\n",
       "      <td>0.55 ± 0.00</td>\n",
       "      <td>0.55 ± 0.00</td>\n",
       "      <td>0.74 ± 0.00</td>\n",
       "      <td>0.22 ± 0.00</td>\n",
       "      <td>0.44 ± 0.00</td>\n",
       "      <td>0.78 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_2</th>\n",
       "      <td>0.60 ± 0.00</td>\n",
       "      <td>0.52 ± 0.00</td>\n",
       "      <td>0.52 ± 0.00</td>\n",
       "      <td>0.74 ± 0.00</td>\n",
       "      <td>0.20 ± 0.00</td>\n",
       "      <td>0.44 ± 0.00</td>\n",
       "      <td>0.77 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_3</th>\n",
       "      <td>0.61 ± 0.00</td>\n",
       "      <td>0.53 ± 0.00</td>\n",
       "      <td>0.54 ± 0.00</td>\n",
       "      <td>0.74 ± 0.00</td>\n",
       "      <td>0.21 ± 0.00</td>\n",
       "      <td>0.45 ± 0.00</td>\n",
       "      <td>0.79 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     AdaBoost Classifier Bagging (Logistic Regression)  \\\n",
       "Dataset                                                       \n",
       "Dataset_0         0.64 ± 0.00                   0.56 ± 0.00   \n",
       "Dataset_1         0.63 ± 0.00                   0.55 ± 0.00   \n",
       "Dataset_2         0.60 ± 0.00                   0.52 ± 0.00   \n",
       "Dataset_3         0.61 ± 0.00                   0.53 ± 0.00   \n",
       "\n",
       "Model     Logistic Regression Random Forest Classifier          SVC  \\\n",
       "Dataset                                                               \n",
       "Dataset_0         0.56 ± 0.00              0.75 ± 0.00  0.23 ± 0.00   \n",
       "Dataset_1         0.55 ± 0.00              0.74 ± 0.00  0.22 ± 0.00   \n",
       "Dataset_2         0.52 ± 0.00              0.74 ± 0.00  0.20 ± 0.00   \n",
       "Dataset_3         0.54 ± 0.00              0.74 ± 0.00  0.21 ± 0.00   \n",
       "\n",
       "Model     Stacking Classifier XGBoost Classifier  \n",
       "Dataset                                           \n",
       "Dataset_0         0.44 ± 0.00        0.79 ± 0.00  \n",
       "Dataset_1         0.44 ± 0.00        0.78 ± 0.00  \n",
       "Dataset_2         0.44 ± 0.00        0.77 ± 0.00  \n",
       "Dataset_3         0.45 ± 0.00        0.79 ± 0.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer la moyenne et l'écart-type du F1-score pour chaque modèle et chaque dataset\n",
    "f1score_summary_df = results_dfa.groupby(['Dataset', 'Model'])['F1 Score'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Calculer la moyenne des écart-types des F1 scores pour chaque modèle\n",
    "average_std = f1score_summary_df.groupby('Model')['std'].mean().reset_index()\n",
    "average_std.rename(columns={'std': 'Average F1 Score Std'}, inplace=True)\n",
    "\n",
    "# Calculer le F1 score avec l'écart-type formaté comme une chaîne (F1 Score ± Std)\n",
    "f1score_summary_df['F1 Score ± Std'] = f1score_summary_df.apply(lambda row: f\"{row['mean']:.2f} ± {row['std']:.2f}\", axis=1)\n",
    "\n",
    "f1score_summary_df['Dataset'] = f1score_summary_df['Dataset'].replace(\n",
    "    'X_train_0', 'Dataset_0').replace('X_train_1', 'Dataset_1').replace(\n",
    "        'X_train_2', 'Dataset_2').replace('X_train_3', 'Dataset_3')\n",
    "\n",
    "# Pivoter la table pour avoir les noms des modèles en colonnes\n",
    "f1score_table = f1score_summary_df.pivot_table(index='Dataset', columns='Model', values='F1 Score ± Std', aggfunc='first')\n",
    "\n",
    "# Afficher le DataFrame pivoté\n",
    "f1score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c265f3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T22:52:57.257891Z",
     "start_time": "2023-10-15T22:52:57.236139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <th>Bagging (Logistic Regression)</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Stacking Classifier</th>\n",
       "      <th>XGBoost Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset_0</th>\n",
       "      <td>27.60 ± 0.11</td>\n",
       "      <td>25.79 ± 0.10</td>\n",
       "      <td>4.03 ± 0.18</td>\n",
       "      <td>35.57 ± 0.10</td>\n",
       "      <td>25.16 ± 0.18</td>\n",
       "      <td>127.82 ± 0.79</td>\n",
       "      <td>9.20 ± 0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_1</th>\n",
       "      <td>27.67 ± 0.16</td>\n",
       "      <td>25.17 ± 0.08</td>\n",
       "      <td>3.95 ± 0.32</td>\n",
       "      <td>35.52 ± 0.26</td>\n",
       "      <td>24.69 ± 0.08</td>\n",
       "      <td>126.03 ± 0.55</td>\n",
       "      <td>9.24 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_2</th>\n",
       "      <td>27.63 ± 0.15</td>\n",
       "      <td>27.12 ± 0.06</td>\n",
       "      <td>4.28 ± 0.34</td>\n",
       "      <td>35.33 ± 0.29</td>\n",
       "      <td>24.65 ± 0.17</td>\n",
       "      <td>125.23 ± 0.90</td>\n",
       "      <td>9.05 ± 0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_3</th>\n",
       "      <td>27.64 ± 0.12</td>\n",
       "      <td>25.71 ± 0.07</td>\n",
       "      <td>4.34 ± 0.21</td>\n",
       "      <td>35.67 ± 0.42</td>\n",
       "      <td>24.24 ± 0.10</td>\n",
       "      <td>123.99 ± 0.44</td>\n",
       "      <td>9.40 ± 1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     AdaBoost Classifier Bagging (Logistic Regression)  \\\n",
       "Dataset                                                       \n",
       "Dataset_0        27.60 ± 0.11                  25.79 ± 0.10   \n",
       "Dataset_1        27.67 ± 0.16                  25.17 ± 0.08   \n",
       "Dataset_2        27.63 ± 0.15                  27.12 ± 0.06   \n",
       "Dataset_3        27.64 ± 0.12                  25.71 ± 0.07   \n",
       "\n",
       "Model     Logistic Regression Random Forest Classifier           SVC  \\\n",
       "Dataset                                                                \n",
       "Dataset_0         4.03 ± 0.18             35.57 ± 0.10  25.16 ± 0.18   \n",
       "Dataset_1         3.95 ± 0.32             35.52 ± 0.26  24.69 ± 0.08   \n",
       "Dataset_2         4.28 ± 0.34             35.33 ± 0.29  24.65 ± 0.17   \n",
       "Dataset_3         4.34 ± 0.21             35.67 ± 0.42  24.24 ± 0.10   \n",
       "\n",
       "Model     Stacking Classifier XGBoost Classifier  \n",
       "Dataset                                           \n",
       "Dataset_0       127.82 ± 0.79        9.20 ± 0.39  \n",
       "Dataset_1       126.03 ± 0.55        9.24 ± 0.32  \n",
       "Dataset_2       125.23 ± 0.90        9.05 ± 0.62  \n",
       "Dataset_3       123.99 ± 0.44        9.40 ± 1.12  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer la moyenne et l'écart-type du temps d'entraînement pour chaque modèle et chaque dataset\n",
    "trainingtime_summary_df = results_dfa.groupby(['Dataset', 'Model'])['Training Time (s)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Calculer le temps d'entraînement avec l'écart-type formaté comme une chaîne (Training Time ± Std)\n",
    "trainingtime_summary_df['Training Time ± Std'] = trainingtime_summary_df.apply(lambda row: f\"{row['mean']:.2f} ± {row['std']:.2f}\", axis=1)\n",
    "\n",
    "trainingtime_summary_df['Dataset'] = trainingtime_summary_df['Dataset'].replace(\n",
    "    'X_train_0', 'Dataset_0').replace('X_train_1', 'Dataset_1').replace(\n",
    "        'X_train_2', 'Dataset_2').replace('X_train_3', 'Dataset_3')\n",
    "\n",
    "# Pivoter la table pour avoir les noms des modèles en colonnes\n",
    "trainingtime_table = trainingtime_summary_df.pivot_table(index='Dataset', columns='Model', values='Training Time ± Std', aggfunc='first')\n",
    "\n",
    "# Afficher le DataFrame pivoté\n",
    "trainingtime_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cae21dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T22:52:59.295690Z",
     "start_time": "2023-10-15T22:52:59.273167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <th>Bagging (Logistic Regression)</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Stacking Classifier</th>\n",
       "      <th>XGBoost Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dataset_0</th>\n",
       "      <td>0.38 ± 0.00</td>\n",
       "      <td>0.04 ± 0.01</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.39 ± 0.01</td>\n",
       "      <td>6.38 ± 0.16</td>\n",
       "      <td>6.55 ± 0.18</td>\n",
       "      <td>0.02 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_1</th>\n",
       "      <td>0.38 ± 0.01</td>\n",
       "      <td>0.05 ± 0.01</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.39 ± 0.00</td>\n",
       "      <td>6.35 ± 0.29</td>\n",
       "      <td>6.46 ± 0.09</td>\n",
       "      <td>0.02 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_2</th>\n",
       "      <td>0.38 ± 0.00</td>\n",
       "      <td>0.04 ± 0.02</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.39 ± 0.01</td>\n",
       "      <td>6.17 ± 0.19</td>\n",
       "      <td>6.41 ± 0.20</td>\n",
       "      <td>0.02 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset_3</th>\n",
       "      <td>0.37 ± 0.01</td>\n",
       "      <td>0.04 ± 0.02</td>\n",
       "      <td>0.01 ± 0.00</td>\n",
       "      <td>0.39 ± 0.01</td>\n",
       "      <td>6.09 ± 0.06</td>\n",
       "      <td>6.39 ± 0.25</td>\n",
       "      <td>0.02 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model     AdaBoost Classifier Bagging (Logistic Regression)  \\\n",
       "Dataset                                                       \n",
       "Dataset_0         0.38 ± 0.00                   0.04 ± 0.01   \n",
       "Dataset_1         0.38 ± 0.01                   0.05 ± 0.01   \n",
       "Dataset_2         0.38 ± 0.00                   0.04 ± 0.02   \n",
       "Dataset_3         0.37 ± 0.01                   0.04 ± 0.02   \n",
       "\n",
       "Model     Logistic Regression Random Forest Classifier          SVC  \\\n",
       "Dataset                                                               \n",
       "Dataset_0         0.00 ± 0.00              0.39 ± 0.01  6.38 ± 0.16   \n",
       "Dataset_1         0.00 ± 0.00              0.39 ± 0.00  6.35 ± 0.29   \n",
       "Dataset_2         0.00 ± 0.00              0.39 ± 0.01  6.17 ± 0.19   \n",
       "Dataset_3         0.01 ± 0.00              0.39 ± 0.01  6.09 ± 0.06   \n",
       "\n",
       "Model     Stacking Classifier XGBoost Classifier  \n",
       "Dataset                                           \n",
       "Dataset_0         6.55 ± 0.18        0.02 ± 0.00  \n",
       "Dataset_1         6.46 ± 0.09        0.02 ± 0.00  \n",
       "Dataset_2         6.41 ± 0.20        0.02 ± 0.00  \n",
       "Dataset_3         6.39 ± 0.25        0.02 ± 0.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer la moyenne et l'écart-type du temps de test pour chaque modèle et chaque dataset\n",
    "testtime_summary_df = results_dfa.groupby(['Dataset', 'Model'])['Test Time (s)'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Calculer le temps de test avec l'écart-type formaté comme une chaîne (Test Time ± Std)\n",
    "testtime_summary_df['Test Time ± Std'] = testtime_summary_df.apply(lambda row: f\"{row['mean']:.2f} ± {row['std']:.2f}\", axis=1)\n",
    "\n",
    "testtime_summary_df['Dataset'] = testtime_summary_df['Dataset'].replace(\n",
    "    'X_train_0', 'Dataset_0').replace('X_train_1', 'Dataset_1').replace(\n",
    "        'X_train_2', 'Dataset_2').replace('X_train_3', 'Dataset_3')\n",
    "\n",
    "# Pivoter la table pour avoir les noms des modèles en colonnes\n",
    "testtime_table = testtime_summary_df.pivot_table(index='Dataset', columns='Model', values='Test Time ± Std', aggfunc='first')\n",
    "\n",
    "# Afficher le DataFrame pivoté\n",
    "testtime_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2dba4",
   "metadata": {},
   "source": [
    "On sauvegarde les différents dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "845a7b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-15T22:54:58.939824Z",
     "start_time": "2023-10-15T22:54:58.927822Z"
    }
   },
   "outputs": [],
   "source": [
    "# resultats globaux\n",
    "results_dfa.to_csv('results/model_resultsv2.csv')\n",
    "\n",
    "#F1_score\n",
    "f1score_summary_df.to_csv('results/F1_score_summary.csv')\n",
    "f1score_table.to_csv('results/F1_SCORE_table.csv')\n",
    "\n",
    "#Training time\n",
    "trainingtime_summary_df.to_csv('results/TrainingTime_summary.csv')\n",
    "trainingtime_table.to_csv('results/TrainingTime_table.csv')\n",
    "\n",
    "#Test time\n",
    "testtime_summary_df.to_csv('results/TestTime_summary.csv')\n",
    "testtime_table.to_csv('results/TestTime_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b78467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
